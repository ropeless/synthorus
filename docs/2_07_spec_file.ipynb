{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23f8a6c8eff7f767",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Spec File #\n",
    "\n",
    "A spec file is a Python file with a single dictionary defined in it. As a spec file is a Python file, comments start with a hash, #.\n",
    "\n",
    "The module `synthorus.spec_file.keys` defines all the reserved words as strings. This can be imported in a spec file to make\n",
    "it easier to read, e.g.,\n",
    "```\n",
    "from synthorus.spec_file.keys import *\n",
    "```\n",
    "You can find many example spec files in the package, `synthorus_demos.demo_files.spec_files`.\n",
    "\n",
    "When Synthorus interprets a nested dictionary in a spec file, a missing key-value pair will be inherited from outer dictionaries, if available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcf5115c45ddb8a",
   "metadata": {},
   "source": [
    "## Spec file grammar ##\n",
    "\n",
    "A spec file dictionary should comply with the format below. The format is described using a modified BNF. Specifically,\n",
    "\n",
    "* upper case is used to denote a grammar component; lower case denotes a string literal unless otherwise indicated\n",
    "\n",
    "* the pipe symbol, `|`,  is used to indicate an optional format.\n",
    "\n",
    "* `XXXX := {` ... `}` is used to indicate the value is a dictionary.\n",
    "\n",
    "* `XXXX := [` ... `]` is used to indicate the value is a list (or tuple or set).\n",
    "\n",
    "\n",
    "```\n",
    "SPEC := {\n",
    "    name:    STRING,       # model name, default is the loaded module file stem.\n",
    "    comment: STRING,       # model comment, default is the loaded module doc string.\n",
    "    author:  STRING,       # model author, default is the loaded module __author__ value.\n",
    "\n",
    "    roots:                        # optional where to find files, default is the current working directory\n",
    "        STRING |                  # a directory path\n",
    "        [ STRING, ...]            # a list of directory paths\n",
    "\n",
    "    rng_n: POSITIVE_INTEGER,      # random number generator security level (for Differential Privacy)\n",
    "                                  #     4 is equivalent to AES128,\n",
    "                                  #     5 is equivalent to AES192,\n",
    "                                  #     6 is equivalent to AES256.\n",
    "\n",
    "    datasources: {\n",
    "        DATASOURCE_ID: DATASOURCE_SPEC,\n",
    "        ...\n",
    "    },\n",
    "\n",
    "    rvs: {                       # if omitted, then all rvs mentioned in all data sources with empty spec\n",
    "        RV_ID: RV_SPEC,\n",
    "        ...                      # optional additional entries\n",
    "    },\n",
    "\n",
    "    crosstabs: {                 # list, tuple, set or dict, if omitted, then empty\n",
    "        CROSSTAB_SPEC,\n",
    "        ...                      # optional additional entries\n",
    "    },\n",
    "\n",
    "    parameters: {                # optional simulation parameters\n",
    "        FIELD_ID: STATE,\n",
    "        ...                      # optional additional entries\n",
    "    },\n",
    "\n",
    "    entities: {                  # optional simulation entities, default is a single entity with all rvs.\n",
    "        ENTITY_ID: ENTITY_SPEC,\n",
    "        ...                      # optional additional entries\n",
    "    },\n",
    "}\n",
    "\n",
    "DATASOURCE_SPEC :=\n",
    "    TEXT_DATASOURCE |                   # Text based datasource, like CSV\n",
    "    BINARY_DATASOURCE |                 # A binary based datasource, like Parquet\n",
    "    DBMS_DATASOURCE |                   # A database with ODBC psycopg driver\n",
    "    FUNCTION_DATASOURCE |               # Mathematically defined dataset\n",
    "\n",
    "TEXT_DATASOURCE := {                     # A text datasource can be inline data or a text file\n",
    "    sensitivity: NON_NEG_NUMBER,         # Differential Privacy parameter\n",
    "    weight: None    |                    # no weight column provided (i.e., every row has weight 1)\n",
    "            INTEGER |                    # index of weight column (just like Python array index)\n",
    "            STRING,                      # name of weight column.\n",
    "    rvs: None |                          # use the rv names as per the data file header line\n",
    "         RV_MAP |                        # map rv ids to columns\n",
    "         RV_LIST,                        # rvs ids in column order (rv id of None or '' means remove column)\n",
    "    define: None | DEFINE_COLUMNS_SPEC,  # mathematically define additional columns.\n",
    "    condition: None | RV_LIST,           # rvs that should not be considered as providing a distribution\n",
    "\n",
    "    location: STRING | None,             # A string file path to data, or None for 'inline' data\n",
    "    inline: STRING | None,               # inline data, or None for file data at a 'location'\n",
    "    data_format: csv |                   # comma separated text file\n",
    "                 tsv |                   # tab separated text file\n",
    "                 table_builder |         # ABS TableBuilder CSV format\n",
    "                 None                    # infer data_format from 'location' file extension\n",
    "    sep: STRING,                         # explicit separator override\n",
    "    header: BOOLEAN,                     # is the first line a header line (default is True)\n",
    "    skip_blank_lines: BOOLEAN,           # skip blank lines (default is True)\n",
    "}\n",
    "\n",
    "BINARY_DATASOURCE := {                   # A binary datasource cannot be inline data.\n",
    "    sensitivity: NON_NEG_NUMBER,         # Differential Privacy parameter\n",
    "    weight: None    |                    # no weight column provided (i.e., every row has weight 1)\n",
    "            INTEGER |                    # index of weight column (just like Python array index)\n",
    "            STRING,                      # name of weight column.\n",
    "    rvs: None   |                        # use the rv names as per the data file header line\n",
    "         RV_MAP |                        # map rv ids to columns\n",
    "         RV_LIST,                        # rvs ids in column order (rv id of None or '' means remove column)\n",
    "    define: None | DEFINE_COLUMNS_SPEC,  # mathematically define additional columns\n",
    "    condition: None | RV_LIST,           # rvs that should not be considered as providing a distribution\n",
    "\n",
    "    data_format: pickle  |               # pickled Pandas dataframe\n",
    "                 parquet |               # Parquet file\n",
    "                 feather,                # Feather file\n",
    "\n",
    "    location: STRING | None              # A string file path, default is the datasource name with appropriate extension\n",
    "}\n",
    "\n",
    "FUNCTION_DATASOURCE := {                 # (implies: sensitivity = 0 and condition = input, unless specified directly)\n",
    "    data_format: function | None,        # optional as the 'function' key gives it away.\n",
    "    function: STRING,                    # a Python expression using input rvs\n",
    "    input: {\n",
    "        RV_ID: STATES                    # list of states or number of states\n",
    "        ...\n",
    "    }\n",
    "    output: | None  # optional, default is the datasource name.\n",
    "}\n",
    "\n",
    "DBMS_DATASOURCE := {\n",
    "    data_format: odbc | postgres,\n",
    "    sensitivity: NON_NEG_NUMBER,         # Differential Privacy parameter\n",
    "    condition: None | RV_LIST,           # rvs that should not be considered as providing a distribution\n",
    "\n",
    "    table: STRING,                       # name of table in the database\n",
    "    schema: STRING | None,               # optional schema where to find the table, default taken from config.DB_SCHEMA\n",
    "    rvs: RV_LIST | None,                 # optional restriction of the columns to query, default is all table columns\n",
    "\n",
    "    connection: None | {                 # optional connection dictionary\n",
    "        # these are database connection parameters\n",
    "        # a value of None means look up the parameter in config using DB_{PARAMETER}\n",
    "        CONN_PARAM: STRING | INTEGER | None,\n",
    "        ...\n",
    "    }\n",
    "}\n",
    "\n",
    "DEFINE_COLUMNS_SPEC := {\n",
    "    RV_ID:                                 # a new column added with this name.\n",
    "           COLUMN_FUNCTION_SPEC |          # values are a function of other columns\n",
    "           COLUMN_GROUP_SPEC,              # values are a grouping of another column\n",
    "    ...\n",
    "}\n",
    "\n",
    "COLUMN_FUNCTION_SPEC := {\n",
    "    function: STRING,                    # a Python expression using input columns\n",
    "    input: RV_LIST,                      # column names to use for input, after any remapping\n",
    "    delete_input: BOOLEAN                # delete the input columns (default is False)\n",
    "}\n",
    "\n",
    "COLUMN_GROUP_SPEC := {\n",
    "    grouping:\n",
    "        group_cut |                      # create groups from a single column using Pandas 'cut'.\n",
    "        group_qcut |                     # create groups from a single column using Pandas 'qcut'.\n",
    "        group_normalise,                 # group values just as categories (multiple input columns permitted)\n",
    "    input: RV_LIST,                      # the source columns to group\n",
    "    size: POSITIVE_INTEGER               # how many groups\n",
    "    delete_input: BOOLEAN                # delete the input column (default is False)\n",
    "}\n",
    "\n",
    "RV_MAP := {\n",
    "    RV_ID: STRING | INTEGER,             # map rv id to column (name or index)\n",
    "    ...\n",
    "}\n",
    "\n",
    "RV_SPEC := {\n",
    "    states: STATES_SPEC,\n",
    "    ensure_none: BOOLEAN | None,         # optional, default is False, ensure states include None\n",
    "    dataset: DATASOURCE_ID | None,       # optional, distribution datasource for this rv\n",
    "}\n",
    "\n",
    "STATES_SPEC :=\n",
    "    STATES             |                 # defined list of states\n",
    "    infer_distinct     |                 # infer from data sources\n",
    "    infer_range        |                 # infer from data sources\n",
    "    infer_max                            # infer from data sources\n",
    "\n",
    "STATES :=\n",
    "    STATE_LIST |                         # list of named states\n",
    "    POSITIVE_INTEGER |                   # number of states, equivalent to Python range(n)\n",
    "    STATE_RANGE                          # equivalent to Python range(start, stop, step)\n",
    "\n",
    "STATE_RANGE := {\n",
    "    start: INTEGER | None,\n",
    "    stop: INTEGER,\n",
    "    step: INTEGER | None,\n",
    "}\n",
    "\n",
    "CROSSTABS_LIST := [        # list, tuple, set\n",
    "        CROSSTAB_SPEC,\n",
    "        ...                # optional additional entries\n",
    "]\n",
    "\n",
    "CROSSTABS_DICT := {\n",
    "        CROSSTAB_ID: CROSSTAB_SPEC,\n",
    "        ...                # optional additional entries\n",
    "}\n",
    "\n",
    "CROSSTAB_SPEC :=\n",
    "    RV_LIST |              # only define as rv list if the datasource is obvious\n",
    "    CROSSTAB_DICT\n",
    "\n",
    "CROSSTAB_DICT := {\n",
    "    rvs: RV_LIST,\n",
    "    epsilon: POSITIVE_NUMBER,       # Differential Privacy number for noise injection\n",
    "    min_cell_size: NON_NEG_NUMBER,  # crosstab rows with weight below this value are removed\n",
    "    need_sensitivity: BOOLEAN       # If True, then no noise applied if sensitivity == 0 (even if min_cell_size > 0)\n",
    "    max_add_rows: POSITIVE_NUMBER   # Differential Privacy limit on adding rows that had zero weight\n",
    "    datasource: None | DATASOURCE_ID\n",
    "}\n",
    "\n",
    "ENTITY_SPEC := {\n",
    "    rvs: RV_LIST | None,                     # fields to populate by sampling random variables\n",
    "    fields: FIELDS_DICT | None,              # fields that are computed, not sampled\n",
    "    id_field: STRING | None,                 # name of the entity 'id' field (default is _id_)\n",
    "    count_field: STRING | None,              # name of the entity 'count' field (default is _count_)\n",
    "    foreign_field: STRING | None             # name of child entity foreign key field (default is {name}_{id_field})\n",
    "    parent: ENTITY_ID | None,                # parent entity (default is None)\n",
    "    cardinality: CARDINALITY_SPEC | None     # define number of records per parent entity (default is 1)\n",
    "}\n",
    "\n",
    "FIELDS_DICT := {\n",
    "    FIELD_ID:\n",
    "        FIELD_CONST_SPEC |\n",
    "        FIELD_SUM_SPEC |\n",
    "        FIELD_FUNCTION_SPEC |\n",
    "        FIELD_SAMPLE_SPEC,\n",
    "    ...                                      # optional additional entries\n",
    "}\n",
    "\n",
    "FIELD_CONST_SPEC := {\n",
    "    value: STATE,                            # field state\n",
    "}\n",
    "\n",
    "FIELD_SAMPLE_SPEC := {\n",
    "    sample: RV_ID\n",
    "}\n",
    "\n",
    "FIELD_SUM_SPEC := {\n",
    "    value: STATE | None,                                        # initial field state (default is 0)\n",
    "    sum: [FIELD_ID | NUMBER, ...] FIELD_ID | NUMBER | None,     # field update method\n",
    "}\n",
    "\n",
    "FIELD_FUNCTION_SPEC := {\n",
    "    value: STATE | None,                 # initial field state (default is None)\n",
    "    function: STRING,                    # a Python expression using input RVs\n",
    "    input: RV_LIST,                      # RV names to use for input\n",
    "}\n",
    "\n",
    "CARDINALITY_SPEC :=\n",
    "    [ CARDINALITY_SPEC, ... ] |                   # list/set of cardinality specs (stop if any indicates stop)\n",
    "    NON_NEG_NUMBER |                              # stop if entity 'count' field >= this value\n",
    "    FIELD_ID |                                    # stop if entity 'count' field >= the value of this rv\n",
    "    {field: FIELD_ID, limit: NON_NEG_NUMBER} |    # stop after rv value is >= the given limit value\n",
    "    {field: FIELD_ID, limit: FIELD_ID} |          # stop after rv value is >= the given limit variable\n",
    "    {field: FIELD_ID, state: STATE | STATE_LIST}  # stop after rv is in one of the specified states\n",
    "\n",
    "\n",
    "RV_LIST := RV_ID | [RV_ID, ...]              # list or tuple with at least one entry (or just a single RV_ID)\n",
    "ENTITY_LIST := ENTITY_ID | [ENTITY_ID, ...]  # list or tuple with at least one entry (or just a single ENTITY_ID)\n",
    "STATE_LIST := [STATE, ...]                   # list, tuple or set with at least one entry\n",
    "\n",
    "STATE := STRING | NUMBER | None\n",
    "\n",
    "DATASOURCE_ID := ID\n",
    "RV_ID := ID\n",
    "CROSSTAB_ID := ID\n",
    "ENTITY_ID := ID\n",
    "FIELD_ID := ID\n",
    "CONN_PARAM := ID\n",
    "\n",
    "BOOLEAN := True | False | yes | no | 1 | 0\n",
    "```\n",
    "\n",
    "`STRING :=` a normal Python string constant\n",
    "\n",
    "`ID :=` a normal Python string constant containing only the characters: a-zA-Z0-9_-.,\n",
    "\n",
    "`NUMBER :=` a normal Python numerical constant (float or int)\n",
    "\n",
    "`NON_NEG_NUMBER :=` a normal Python numerical constant (float or int), >= 0\n",
    "\n",
    "`POSITIVE_NUMBER :=` a normal Python numerical constant (float or int), > 0\n",
    "\n",
    "`INTEGER :=` a normal Python integer constant\n",
    "\n",
    "`NON_NEG_INTEGER :=` a normal Python integer constant, >= 0\n",
    "\n",
    "`POSITIVE_INTEGER :=` a normal Python integer constant, > 0\n",
    "\n",
    "`None :=` can be either the Python None object or just omit the 'key:value' pair in the dictionary.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Example spec files ##\n",
    "\n",
    "A spec file can be loaded from file using `load_spec_file` in module `synthorus.spec_file`. This method opens the file and load a Python dictionary (it may also update some default values). It then calls `interpret_spec_file` passing the loaded Python dictionary.\n",
    "\n",
    "\n",
    "A minimal spec file must specify its datasources, however, this may be empty as the following example shows.\n",
    "\n",
    "Even though there are no datasources, random variables or cross-tables, the resulting model spec still contains the default entity."
   ],
   "id": "48fc0b537ebccea9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T02:08:40.637235Z",
     "start_time": "2025-11-18T02:08:39.966940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from synthorus.spec_file.interpret_spec_file import interpret_spec_file\n",
    "from synthorus.model.model_spec import ModelSpec\n",
    "\n",
    "spec_file_dict = {\n",
    "    'datasources': {}\n",
    "}\n",
    "\n",
    "model_spec: ModelSpec = interpret_spec_file(spec_file_dict)\n",
    "\n",
    "print(model_spec.model_dump_json(indent=2))"
   ],
   "id": "bacb3a86783362a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"_unknown_\",\n",
      "  \"author\": \"_unknown_\",\n",
      "  \"comment\": \"\",\n",
      "  \"roots\": [],\n",
      "  \"rng_n\": 4,\n",
      "  \"datasources\": {},\n",
      "  \"rvs\": {},\n",
      "  \"crosstabs\": {},\n",
      "  \"entities\": {\n",
      "    \"_default_entity_\": {\n",
      "      \"id_field_name\": \"_id_\",\n",
      "      \"count_field_name\": \"_count_\",\n",
      "      \"foreign_field_name\": null,\n",
      "      \"fields\": {},\n",
      "      \"cardinality\": [],\n",
      "      \"parent\": null\n",
      "    }\n",
      "  },\n",
      "  \"parameters\": {}\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To prove this is a valid spec file, we build and run a simulator from it.",
   "id": "24bb200595b44019"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T02:13:45.330526Z",
     "start_time": "2025-11-18T02:13:45.307716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from synthorus.simulator.make_simulator_from_simulator_spec import make_simulator_from_simulator_spec\n",
    "from synthorus.simulator.make_simulator_spec_from_model_spec import make_simulator_spec_from_model_spec\n",
    "from synthorus.simulator.simulator_spec import SimulatorSpec\n",
    "from synthorus.simulator.simulator import Simulator\n",
    "from synthorus.simulator.sim_recorder import DebugRecorder\n",
    "\n",
    "simulator_spec: SimulatorSpec = make_simulator_spec_from_model_spec(model_spec)\n",
    "simulator: Simulator = make_simulator_from_simulator_spec(simulator_spec, samplers={})\n",
    "\n",
    "simulator.run(DebugRecorder(), iterations=5)"
   ],
   "id": "2beb95424609a272",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: _default_entity_ ['_id_', '_count_']\n",
      "\n",
      "_default_entity_ [('_id_', 1), ('_count_', 1)]\n",
      "_default_entity_ [('_id_', 2), ('_count_', 1)]\n",
      "_default_entity_ [('_id_', 3), ('_count_', 1)]\n",
      "_default_entity_ [('_id_', 4), ('_count_', 1)]\n",
      "_default_entity_ [('_id_', 5), ('_count_', 1)]\n",
      "\n",
      "Finished\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
