{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23f8a6c8eff7f767",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Spec File #\n",
    "\n",
    "A spec file is a Python file with a single dictionary defined in it. As a spec file is a Python file, comments start with a hash, #.\n",
    "\n",
    "The module `synthorus.spec_file.keys` defines all the reserved words as strings. This can be imported in a spec file to make\n",
    "it easier to read, e.g.,\n",
    "```\n",
    "from synthorus.spec_file.keys import *\n",
    "```\n",
    "You can find many example spec files in the package, `synthorus_demos.demo_files.spec_files`.\n",
    "\n",
    "When Synthorus interprets a nested dictionary in a spec file, a missing key-value pair will be inherited from outer dictionaries, if available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcf5115c45ddb8a",
   "metadata": {},
   "source": [
    "## Spec file grammar ##\n",
    "\n",
    "A spec file dictionary should comply with the format below. The format is described using a modified BNF. Specifically,\n",
    "\n",
    "* upper case is used to denote a grammar component; lower case denotes a string literal unless otherwise indicated\n",
    "\n",
    "* the pipe symbol, `|`,  is used to indicate an optional format.\n",
    "\n",
    "* `XXXX := {` ... `}` is used to indicate the value is a dictionary.\n",
    "\n",
    "* `XXXX := [` ... `]` is used to indicate the value is a list (or tuple or set).\n",
    "\n",
    "\n",
    "```\n",
    "SPEC := {\n",
    "    name:    STRING,       # model name, default is the loaded module file stem.\n",
    "    comment: STRING,       # model comment, default is the loaded module doc string.\n",
    "    author:  STRING,       # model author, default is the loaded module __author__ value.\n",
    "\n",
    "    roots:                        # optional where to find files, default is the current working directory\n",
    "        STRING |                  # a directory path\n",
    "        [ STRING, ...]            # a list of directory paths\n",
    "\n",
    "    rng_n: POSITIVE_INTEGER,      # random number generator security level (for Differential Privacy)\n",
    "                                  #     4 is equivalent to AES128,\n",
    "                                  #     5 is equivalent to AES192,\n",
    "                                  #     6 is equivalent to AES256.\n",
    "\n",
    "    datasources: {\n",
    "        DATASOURCE_ID: DATASOURCE_SPEC,\n",
    "        ...\n",
    "    },\n",
    "\n",
    "    rvs: {                       # if omitted, then all rvs mentioned in all datasources is used, with empty rv spec\n",
    "        RV_ID: RV_SPEC,\n",
    "        ...                      # optional additional entries\n",
    "    },\n",
    "\n",
    "    crosstabs: {                 # list, tuple, set or dict, if omitted, then empty\n",
    "        CROSSTAB_SPEC,\n",
    "        ...                      # optional additional entries\n",
    "    },\n",
    "\n",
    "    parameters: {                # optional simulation parameters\n",
    "        FIELD_ID: STATE,\n",
    "        ...                      # optional additional entries\n",
    "    },\n",
    "\n",
    "    entities: {                  # optional simulation entities, default is a single entity with all rvs.\n",
    "        ENTITY_ID: ENTITY_SPEC,\n",
    "        ...                      # optional additional entries\n",
    "    },\n",
    "}\n",
    "\n",
    "DATASOURCE_SPEC :=\n",
    "    TEXT_DATASOURCE |                   # Text based datasource, like CSV\n",
    "    BINARY_DATASOURCE |                 # A binary based datasource, like Parquet\n",
    "    DBMS_DATASOURCE |                   # A database with ODBC psycopg driver\n",
    "    FUNCTION_DATASOURCE |               # Mathematically defined dataset\n",
    "\n",
    "TEXT_DATASOURCE := {                     # A text datasource can be inline data or a text file\n",
    "    sensitivity: NON_NEG_NUMBER,         # Differential Privacy parameter\n",
    "    weight: None    |                    # no weight column provided (i.e., every row has weight 1)\n",
    "            INTEGER |                    # index of weight column (just like Python array index)\n",
    "            STRING,                      # name of weight column.\n",
    "    rvs: None |                          # use the rv names as per the data file header line\n",
    "         RV_MAP |                        # map rv ids to columns\n",
    "         RV_LIST,                        # rvs ids in column order (rv id of None or '' means remove column)\n",
    "    define: None | DEFINE_COLUMNS_SPEC,  # mathematically define additional columns.\n",
    "    condition: None | RV_LIST,           # rvs that should not be considered as providing a distribution\n",
    "\n",
    "    location: STRING | None,             # A string file path to data, or None for 'inline' data\n",
    "    inline: STRING | None,               # inline data, or None for file data at a 'location'\n",
    "    data_format: csv |                   # comma separated text file\n",
    "                 tsv |                   # tab separated text file\n",
    "                 table_builder |         # ABS TableBuilder CSV format\n",
    "                 None                    # infer data_format from 'location' file extension\n",
    "    sep: STRING,                         # explicit separator override\n",
    "    header: BOOLEAN,                     # is the first line a header line (default is True)\n",
    "    skip_blank_lines: BOOLEAN,           # skip blank lines (default is True)\n",
    "}\n",
    "\n",
    "BINARY_DATASOURCE := {                   # A binary datasource cannot be inline data.\n",
    "    sensitivity: NON_NEG_NUMBER,         # Differential Privacy parameter\n",
    "    weight: None    |                    # no weight column provided (i.e., every row has weight 1)\n",
    "            INTEGER |                    # index of weight column (just like Python array index)\n",
    "            STRING,                      # name of weight column.\n",
    "    rvs: None   |                        # use the rv names as per the data file header line\n",
    "         RV_MAP |                        # map rv ids to columns\n",
    "         RV_LIST,                        # rvs ids in column order (rv id of None or '' means remove column)\n",
    "    define: None | DEFINE_COLUMNS_SPEC,  # mathematically define additional columns\n",
    "    condition: None | RV_LIST,           # rvs that should not be considered as providing a distribution\n",
    "\n",
    "    data_format: pickle  |               # pickled Pandas dataframe\n",
    "                 parquet |               # Parquet file\n",
    "                 feather,                # Feather file\n",
    "\n",
    "    location: STRING | None              # A string file path, default is the datasource name with appropriate extension\n",
    "}\n",
    "\n",
    "FUNCTION_DATASOURCE := {                 # (implies: sensitivity = 0 and condition = input, unless specified directly)\n",
    "    data_format: function | None,        # optional as the 'function' key gives it away.\n",
    "    function: STRING,                    # a Python expression using input rvs\n",
    "    input: {\n",
    "        RV_ID: STATES                    # list of states or number of states\n",
    "        ...\n",
    "    }\n",
    "    output: | None  # optional, default is the datasource name.\n",
    "}\n",
    "\n",
    "DBMS_DATASOURCE := {\n",
    "    data_format: odbc | postgres,\n",
    "    sensitivity: NON_NEG_NUMBER,         # Differential Privacy parameter\n",
    "    condition: None | RV_LIST,           # rvs that should not be considered as providing a distribution\n",
    "\n",
    "    table: STRING,                       # name of table in the database\n",
    "    schema: STRING | None,               # optional schema where to find the table, default taken from config.DB_SCHEMA\n",
    "    rvs: RV_LIST | None,                 # optional restriction of the columns to query, default is all table columns\n",
    "\n",
    "    connection: None | {                 # optional connection dictionary\n",
    "        # these are database connection parameters\n",
    "        # a value of None means look up the parameter in config using DB_{PARAMETER}\n",
    "        CONN_PARAM: STRING | INTEGER | None,\n",
    "        ...\n",
    "    }\n",
    "}\n",
    "\n",
    "DEFINE_COLUMNS_SPEC := {\n",
    "    RV_ID:                                 # a new column added with this name.\n",
    "           COLUMN_FUNCTION_SPEC |          # values are a function of other columns\n",
    "           COLUMN_GROUP_SPEC,              # values are a grouping of another column\n",
    "    ...\n",
    "}\n",
    "\n",
    "COLUMN_FUNCTION_SPEC := {\n",
    "    function: STRING,                    # a Python expression using input columns\n",
    "    input: RV_LIST,                      # column names to use for input, after any remapping\n",
    "    delete_input: BOOLEAN                # delete the input columns (default is False)\n",
    "}\n",
    "\n",
    "COLUMN_GROUP_SPEC := {\n",
    "    grouping:\n",
    "        group_cut |                      # create groups from a single column using Pandas 'cut'.\n",
    "        group_qcut |                     # create groups from a single column using Pandas 'qcut'.\n",
    "        group_normalise,                 # group values just as categories (multiple input columns permitted)\n",
    "    input: RV_LIST,                      # the source columns to group\n",
    "    size: POSITIVE_INTEGER               # how many groups\n",
    "    delete_input: BOOLEAN                # delete the input column (default is False)\n",
    "}\n",
    "\n",
    "RV_MAP := {\n",
    "    RV_ID: STRING | INTEGER,             # map rv id to column (name or index)\n",
    "    ...\n",
    "}\n",
    "\n",
    "RV_SPEC := {\n",
    "    states: STATES_SPEC,\n",
    "    ensure_none: BOOLEAN | None,         # optional, default is False, ensure states include None\n",
    "    dataset: DATASOURCE_ID | None,       # optional, distribution datasource for this rv\n",
    "}\n",
    "\n",
    "STATES_SPEC :=\n",
    "    STATES             |                 # defined list of states\n",
    "    infer_distinct     |                 # infer from datasources\n",
    "    infer_range        |                 # infer from datasources\n",
    "    infer_max                            # infer from datasources\n",
    "\n",
    "STATES :=\n",
    "    STATE_LIST |                         # list of named states\n",
    "    POSITIVE_INTEGER |                   # number of states, equivalent to Python range(n)\n",
    "    STATE_RANGE                          # equivalent to Python range(start, stop, step)\n",
    "\n",
    "STATE_RANGE := {\n",
    "    start: INTEGER | None,\n",
    "    stop: INTEGER,\n",
    "    step: INTEGER | None,\n",
    "}\n",
    "\n",
    "CROSSTABS_LIST := [        # list, tuple, set\n",
    "        CROSSTAB_SPEC,\n",
    "        ...                # optional additional entries\n",
    "]\n",
    "\n",
    "CROSSTABS_DICT := {\n",
    "        CROSSTAB_ID: CROSSTAB_SPEC,\n",
    "        ...                # optional additional entries\n",
    "}\n",
    "\n",
    "CROSSTAB_SPEC :=\n",
    "    RV_LIST |              # only define as rv list if the datasource is obvious\n",
    "    CROSSTAB_DICT\n",
    "\n",
    "CROSSTAB_DICT := {\n",
    "    rvs: RV_LIST,\n",
    "    epsilon: POSITIVE_NUMBER,       # Differential Privacy number for noise injection\n",
    "    min_cell_size: NON_NEG_NUMBER,  # crosstab rows with weight below this value are removed\n",
    "    need_sensitivity: BOOLEAN       # If True, then no noise applied if sensitivity == 0 (even if min_cell_size > 0)\n",
    "    max_add_rows: POSITIVE_NUMBER   # Differential Privacy limit on adding rows that had zero weight\n",
    "    datasource: None | DATASOURCE_ID\n",
    "}\n",
    "\n",
    "ENTITY_SPEC := {\n",
    "    rvs: RV_LIST | None,                     # fields to populate by sampling random variables\n",
    "    fields: FIELDS_DICT | None,              # fields that are computed, not sampled\n",
    "    id_field: STRING | None,                 # name of the entity 'id' field (default is _id_)\n",
    "    count_field: STRING | None,              # name of the entity 'count' field (default is _count_)\n",
    "    foreign_field: STRING | None             # name of child entity foreign key field (default is {name}_{id_field})\n",
    "    parent: ENTITY_ID | None,                # parent entity (default is None)\n",
    "    cardinality: CARDINALITY_SPEC | None     # define number of records per parent entity (default is 1)\n",
    "}\n",
    "\n",
    "FIELDS_DICT := {\n",
    "    FIELD_ID:\n",
    "        FIELD_CONST_SPEC |\n",
    "        FIELD_SUM_SPEC |\n",
    "        FIELD_FUNCTION_SPEC |\n",
    "        FIELD_SAMPLE_SPEC,\n",
    "    ...                                      # optional additional entries\n",
    "}\n",
    "\n",
    "FIELD_CONST_SPEC := {\n",
    "    value: STATE,                            # field state\n",
    "}\n",
    "\n",
    "FIELD_SAMPLE_SPEC := {\n",
    "    sample: RV_ID\n",
    "}\n",
    "\n",
    "FIELD_SUM_SPEC := {\n",
    "    value: STATE | None,                                        # initial field state (default is 0)\n",
    "    sum: [FIELD_ID | NUMBER, ...] FIELD_ID | NUMBER | None,     # field update method\n",
    "}\n",
    "\n",
    "FIELD_FUNCTION_SPEC := {\n",
    "    value: STATE | None,                 # initial field state (default is None)\n",
    "    function: STRING,                    # a Python expression using input RVs\n",
    "    input: RV_LIST,                      # RV names to use for input\n",
    "}\n",
    "\n",
    "CARDINALITY_SPEC :=\n",
    "    [ CARDINALITY_SPEC, ... ] |                   # list/set of cardinality specs (stop if any indicates stop)\n",
    "    NON_NEG_NUMBER |                              # stop if entity 'count' field >= this value\n",
    "    FIELD_ID |                                    # stop if entity 'count' field >= the value of this rv\n",
    "    {field: FIELD_ID, limit: NON_NEG_NUMBER} |    # stop after rv value is >= the given limit value\n",
    "    {field: FIELD_ID, limit: FIELD_ID} |          # stop after rv value is >= the given limit variable\n",
    "    {field: FIELD_ID, state: STATE | STATE_LIST}  # stop after rv is in one of the specified states\n",
    "\n",
    "\n",
    "RV_LIST := RV_ID | [RV_ID, ...]              # list or tuple with at least one entry (or just a single RV_ID)\n",
    "ENTITY_LIST := ENTITY_ID | [ENTITY_ID, ...]  # list or tuple with at least one entry (or just a single ENTITY_ID)\n",
    "STATE_LIST := [STATE, ...]                   # list, tuple or set with at least one entry\n",
    "\n",
    "STATE := STRING | NUMBER | None\n",
    "\n",
    "DATASOURCE_ID := ID\n",
    "RV_ID := ID\n",
    "CROSSTAB_ID := ID\n",
    "ENTITY_ID := ID\n",
    "FIELD_ID := ID\n",
    "CONN_PARAM := ID\n",
    "\n",
    "BOOLEAN := True | False | yes | no | 1 | 0\n",
    "```\n",
    "\n",
    "`STRING :=` a normal Python string constant\n",
    "\n",
    "`ID :=` a normal Python string constant containing only the characters: a-zA-Z0-9_-.,\n",
    "\n",
    "`NUMBER :=` a normal Python numerical constant (float or int)\n",
    "\n",
    "`NON_NEG_NUMBER :=` a normal Python numerical constant (float or int), >= 0\n",
    "\n",
    "`POSITIVE_NUMBER :=` a normal Python numerical constant (float or int), > 0\n",
    "\n",
    "`INTEGER :=` a normal Python integer constant\n",
    "\n",
    "`NON_NEG_INTEGER :=` a normal Python integer constant, >= 0\n",
    "\n",
    "`POSITIVE_INTEGER :=` a normal Python integer constant, > 0\n",
    "\n",
    "`None :=` can be either the Python None object or just omit the 'key:value' pair in the dictionary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fc0b537ebccea9",
   "metadata": {},
   "source": [
    "## Example spec files ##\n",
    "\n",
    "A spec file can be loaded from file using `load_spec_file` in module `synthorus.spec_file`. This method opens the file and load a Python dictionary (it may also update some default values). It then calls `interpret_spec_file` passing the loaded Python dictionary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e97b0941d594fd6",
   "metadata": {},
   "source": [
    "### Minimal spec file ###\n",
    "\n",
    "A minimal spec file must specify its datasources, however, this may be empty as the following example shows.\n",
    "\n",
    "Even though there are no datasources, random variables or cross-tables, the resulting model spec still contains the default entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bacb3a86783362a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T21:36:34.445314Z",
     "iopub.status.busy": "2025-11-19T21:36:34.445314Z",
     "iopub.status.idle": "2025-11-19T21:36:34.668927Z",
     "shell.execute_reply": "2025-11-19T21:36:34.668914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"_unknown_\",\n",
      "  \"author\": \"_unknown_\",\n",
      "  \"comment\": \"\",\n",
      "  \"roots\": [],\n",
      "  \"rng_n\": 4,\n",
      "  \"datasources\": {},\n",
      "  \"rvs\": {},\n",
      "  \"crosstabs\": {},\n",
      "  \"entities\": {\n",
      "    \"_default_entity_\": {\n",
      "      \"id_field_name\": \"_id_\",\n",
      "      \"count_field_name\": \"_count_\",\n",
      "      \"foreign_field_name\": null,\n",
      "      \"fields\": {},\n",
      "      \"cardinality\": [],\n",
      "      \"parent\": null\n",
      "    }\n",
      "  },\n",
      "  \"parameters\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from synthorus.spec_file.interpret_spec_file import interpret_spec_file\n",
    "from synthorus.model.model_spec import ModelSpec\n",
    "\n",
    "spec_file_dict = {\n",
    "    'datasources': {}\n",
    "}\n",
    "\n",
    "model_spec: ModelSpec = interpret_spec_file(spec_file_dict)\n",
    "\n",
    "print(model_spec.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bb200595b44019",
   "metadata": {},
   "source": [
    "To prove this is a valid spec file, we build and run a simulator from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2beb95424609a272",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T21:36:34.670928Z",
     "iopub.status.busy": "2025-11-19T21:36:34.670928Z",
     "iopub.status.idle": "2025-11-19T21:36:34.687371Z",
     "shell.execute_reply": "2025-11-19T21:36:34.687371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: _default_entity_ ['_id_', '_count_']\n",
      "\n",
      "_default_entity_ [('_id_', 1), ('_count_', 1)]\n",
      "_default_entity_ [('_id_', 2), ('_count_', 1)]\n",
      "_default_entity_ [('_id_', 3), ('_count_', 1)]\n",
      "_default_entity_ [('_id_', 4), ('_count_', 1)]\n",
      "_default_entity_ [('_id_', 5), ('_count_', 1)]\n",
      "\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "from synthorus.simulator.make_simulator_from_simulator_spec import make_simulator_from_simulator_spec\n",
    "from synthorus.simulator.make_simulator_spec_from_model_spec import make_simulator_spec_from_model_spec\n",
    "from synthorus.simulator.simulator_spec import SimulatorSpec\n",
    "from synthorus.simulator.simulator import Simulator\n",
    "from synthorus.simulator.sim_recorder import DebugRecorder\n",
    "\n",
    "simulator_spec: SimulatorSpec = make_simulator_spec_from_model_spec(model_spec)\n",
    "simulator: Simulator = make_simulator_from_simulator_spec(simulator_spec, samplers={})\n",
    "\n",
    "simulator.run(DebugRecorder(), iterations=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e224ee1e4c7276e",
   "metadata": {},
   "source": [
    "### Tiny spec file ###\n",
    "\n",
    "Here is an example spec file from `synthorus_demos`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f84d0e77f830d76f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T21:36:34.689377Z",
     "iopub.status.busy": "2025-11-19T21:36:34.689377Z",
     "iopub.status.idle": "2025-11-19T21:36:34.698203Z",
     "shell.execute_reply": "2025-11-19T21:36:34.698203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\n",
      "This is an example simple Synthorus spec file.\n",
      "\"\"\"\n",
      "from synthorus.spec_file.keys import *\n",
      "\n",
      "spec = {\n",
      "    sensitivity: 0,  # no data is sensitive data\n",
      "    min_cell_size: 0,  # no data will be redacted\n",
      "\n",
      "    states: infer_distinct,  # default for all random variables\n",
      "\n",
      "    datasources: {\n",
      "        'xyz': {\n",
      "            data_format: csv,\n",
      "            inline: \"\"\"\n",
      "                X,Y,Z\n",
      "                y,y,y\n",
      "                y,y,n\n",
      "                y,n,y\n",
      "                y,n,n\n",
      "                n,y,y\n",
      "                n,y,n\n",
      "                n,n,y\n",
      "                n,n,n\n",
      "                \"\"\"\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from synthorus_demos.utils.file_helper import cat\n",
    "from synthorus_demos.demo_files import SPEC_FILES\n",
    "\n",
    "file_path = SPEC_FILES / 'spec_tiny.py'\n",
    "\n",
    "cat(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee84ffefe12b5a50",
   "metadata": {},
   "source": [
    "Here we load `spec_tiny.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b840713287f741c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T21:36:34.700207Z",
     "iopub.status.busy": "2025-11-19T21:36:34.700207Z",
     "iopub.status.idle": "2025-11-19T21:36:34.706886Z",
     "shell.execute_reply": "2025-11-19T21:36:34.706886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"spec_tiny\",\n",
      "  \"author\": \"_unknown_\",\n",
      "  \"comment\": \"This is an example simple Synthorus spec file.\",\n",
      "  \"roots\": [],\n",
      "  \"rng_n\": 4,\n",
      "  \"datasources\": {\n",
      "    \"xyz\": {\n",
      "      \"sensitivity\": 0.0,\n",
      "      \"rvs\": [\n",
      "        \"X\",\n",
      "        \"Y\",\n",
      "        \"Z\"\n",
      "      ],\n",
      "      \"dataset_spec\": {\n",
      "        \"type\": \"csv\",\n",
      "        \"weight\": null,\n",
      "        \"rv_map\": null,\n",
      "        \"rv_define\": {},\n",
      "        \"input\": {\n",
      "          \"type\": \"inline\",\n",
      "          \"inline\": \"X,Y,Z\\ny,y,y\\ny,y,n\\ny,n,y\\ny,n,n\\nn,y,y\\nn,y,n\\nn,n,y\\nn,n,n\\n\"\n",
      "        },\n",
      "        \"sep\": \",\",\n",
      "        \"header\": true,\n",
      "        \"skip_blank_lines\": true,\n",
      "        \"skip_initial_space\": true\n",
      "      },\n",
      "      \"non_distribution_rvs\": []\n",
      "    }\n",
      "  },\n",
      "  \"rvs\": {\n",
      "    \"Y\": {\n",
      "      \"states\": \"infer_distinct\",\n",
      "      \"ensure_none\": false\n",
      "    },\n",
      "    \"X\": {\n",
      "      \"states\": \"infer_distinct\",\n",
      "      \"ensure_none\": false\n",
      "    },\n",
      "    \"Z\": {\n",
      "      \"states\": \"infer_distinct\",\n",
      "      \"ensure_none\": false\n",
      "    }\n",
      "  },\n",
      "  \"crosstabs\": {\n",
      "    \"_Y\": {\n",
      "      \"rvs\": [\n",
      "        \"Y\"\n",
      "      ],\n",
      "      \"datasource\": \"xyz\",\n",
      "      \"epsilon\": 0.1,\n",
      "      \"min_cell_size\": 0.0,\n",
      "      \"max_add_rows\": 1000000\n",
      "    },\n",
      "    \"_X\": {\n",
      "      \"rvs\": [\n",
      "        \"X\"\n",
      "      ],\n",
      "      \"datasource\": \"xyz\",\n",
      "      \"epsilon\": 0.1,\n",
      "      \"min_cell_size\": 0.0,\n",
      "      \"max_add_rows\": 1000000\n",
      "    },\n",
      "    \"_Z\": {\n",
      "      \"rvs\": [\n",
      "        \"Z\"\n",
      "      ],\n",
      "      \"datasource\": \"xyz\",\n",
      "      \"epsilon\": 0.1,\n",
      "      \"min_cell_size\": 0.0,\n",
      "      \"max_add_rows\": 1000000\n",
      "    }\n",
      "  },\n",
      "  \"entities\": {\n",
      "    \"_default_entity_\": {\n",
      "      \"id_field_name\": \"_id_\",\n",
      "      \"count_field_name\": \"_count_\",\n",
      "      \"foreign_field_name\": null,\n",
      "      \"fields\": {\n",
      "        \"Y\": {\n",
      "          \"type\": \"sample\",\n",
      "          \"rv_name\": \"Y\"\n",
      "        },\n",
      "        \"X\": {\n",
      "          \"type\": \"sample\",\n",
      "          \"rv_name\": \"X\"\n",
      "        },\n",
      "        \"Z\": {\n",
      "          \"type\": \"sample\",\n",
      "          \"rv_name\": \"Z\"\n",
      "        }\n",
      "      },\n",
      "      \"cardinality\": [],\n",
      "      \"parent\": null\n",
      "    }\n",
      "  },\n",
      "  \"parameters\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from synthorus.spec_file.interpret_spec_file import load_spec_file\n",
    "\n",
    "model_spec: ModelSpec = load_spec_file(file_path)\n",
    "\n",
    "print(model_spec.model_dump_json(indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df7228b48a75f61",
   "metadata": {},
   "source": [
    "Here is a simulation using `spec_tiny.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2717b9c432312750",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T21:36:34.708892Z",
     "iopub.status.busy": "2025-11-19T21:36:34.708892Z",
     "iopub.status.idle": "2025-11-19T21:36:35.433610Z",
     "shell.execute_reply": "2025-11-19T21:36:35.433610Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: _default_entity_ ['_id_', '_count_', 'Y', 'X', 'Z']\n",
      "\n",
      "_default_entity_ [('_id_', 1), ('_count_', 1), ('Y', 'n'), ('X', 'n'), ('Z', 'y')]\n",
      "_default_entity_ [('_id_', 2), ('_count_', 1), ('Y', 'y'), ('X', 'y'), ('Z', 'n')]\n",
      "_default_entity_ [('_id_', 3), ('_count_', 1), ('Y', 'n'), ('X', 'y'), ('Z', 'n')]\n",
      "_default_entity_ [('_id_', 4), ('_count_', 1), ('Y', 'y'), ('X', 'n'), ('Z', 'n')]\n",
      "_default_entity_ [('_id_', 5), ('_count_', 1), ('Y', 'n'), ('X', 'n'), ('Z', 'y')]\n",
      "_default_entity_ [('_id_', 6), ('_count_', 1), ('Y', 'y'), ('X', 'n'), ('Z', 'y')]\n",
      "_default_entity_ [('_id_', 7), ('_count_', 1), ('Y', 'y'), ('X', 'n'), ('Z', 'y')]\n",
      "_default_entity_ [('_id_', 8), ('_count_', 1), ('Y', 'n'), ('X', 'y'), ('Z', 'n')]\n",
      "\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "from synthorus.utils.print_function import NO_LOG\n",
    "from synthorus.workflows.make_simulator_from_files import make_simulator_from_files\n",
    "from synthorus.workflows.make_model_definition_files import make_model_definition_files\n",
    "from synthorus_demos.utils.output_directory import output_directory\n",
    "\n",
    "with output_directory('demo_spec_tiny', overwrite=True) as model_definition_dir:\n",
    "    make_model_definition_files(model_spec, model_definition_dir, log=NO_LOG)\n",
    "    simulator: Simulator = make_simulator_from_files(model_definition_dir, log=NO_LOG)\n",
    "\n",
    "simulator.run(DebugRecorder(), iterations=8)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
