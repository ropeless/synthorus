import math
from random import SystemRandom

from scipy.stats import norm


class SafeRandom:
    """
    SafeRandom is a random number generator, specifically designed for
    differential privacy, with cryptographic strength.

    Random variates are based on ‘SystemRandom’ which accesses the most secure
    source of randomness provided by the operating system. However, all random
    variates from SystemRandom are treated as unsafe. A safe random variate is
    generated by combining multiple SystemRandom variates.

    For details of random variate production, see:
    Holohan, N., & Braghin, S. (2021, October). Secure random sampling in differential privacy.
    In European Symposium on Research in Computer Security (pp. 523-542). Springer, Cham.
    https://doi.org/10.1007/978-3-030-88428-4_26.
    """
    __slots__ = ('_n', '_sqrt_n')

    _unsafe_rand = SystemRandom()

    def __init__(self, n: int):
        """
        Args:
            n: is a positive integer to control level of security.
                4 is equivalent to AES128,
                5 is equivalent to AES192,
                6 is equivalent to AES256.
        """
        assert isinstance(n, int) and n > 0, 'SafeRandom n must be a positive integer'
        self._n = n
        self._sqrt_n = math.sqrt(n)

    @property
    def n(self) -> int:
        """
        The positive integer to control level of security.
            4 is equivalent to AES128,
            5 is equivalent to AES192,
            6 is equivalent to AES256.
        """
        return self._n

    def random(self) -> float:
        """
        Provide a random variate uniform in the interval [0, 1).
        """
        # This is equivalent to making a random choice from n
        # self._unsafe_random() options.
        for _ in range(self.uniform(self._n)):
            self._unsafe_random()
        return self._unsafe_random()

    def random_open(self) -> float:
        """
        Return a uniform random variate in (0, 1)
        """
        # This is a simple rejection sampler, sampling from [0, 1).
        u = 0
        while u == 0:
            u = self.random()
        return u

    def uniform(self, n: int) -> int:
        """
        Return a safe uniform random integer in [0, n),
        suitable for small-medium values of n.
        Method:
          1. generate a safe Gaussian random variate from N(0, 1)
          2. convert it to a uniform random variate using norm.cdf
          3. truncate to the integer range [0, len(options) - 1] to protect from precision errors.
        """
        g = self._gauss_sum() / self._sqrt_n
        u = norm.cdf(g) * n
        return max(0, min(int(u), n - 1))

    def gauss(self, mu: float, sigma: float) -> float:
        """
        Provide a Gaussian random variate with scale mean of 'mu'
        and standard deviation of 'sigma'.
        Assumes sigma > 0.

        The PDF is: p(x | mu, sigma) = 1/(sigma sqrt(2 pi)) exp(-1/2 ((x - mu)/sigma)^2).
        Mean is mu.
        Variance is sigma^2.
        """
        return mu + sigma * self._gauss_sum() / self._sqrt_n

    def laplace(self, mu: float, b: float) -> float:
        """
        Provide a Laplace random variate with offset 'mu' and scale 'b'.
        Assumes b > 0. As b increases, the variance of the
        random variates increases.

        The PDF is: p(x | mu, b) = 1/(2b) exp(-|x - mu|/b).
        Mean is mu.
        Variance is 2 b^2.
        """
        return mu + b * (
                self._gauss_sum() * self._gauss_sum()
                - self._gauss_sum() * self._gauss_sum()
        ) / self._n

    def binomial(self, n: int, p: float) -> int:
        """
        Provide a Binomial random variate, k.
        Assumes n is a positive integer.
        Assumes 0 < p < 1.

        The PMF is P(k | n, p) = (n k) p^k (1-p)^(n-k).
        Mean is np.
        Variance is np(1-p).
        """
        assert n >= 1, 'binomial: n must be a positive integer'

        # Use normal approximation if n * p and n * (1 - p) are
        # above this threshold.
        normal_approx_thresh = 100

        if n * p > normal_approx_thresh and n * (1 - p) > normal_approx_thresh:
            k = self._normal_approx_to_binomial(n, p)
        else:
            k = self._algorithm_bin(n, p)

        return k

    def truncated_laplace(self, r: float, b: float) -> float:
        """
        Provide a Laplace random variate with limit 'r' and scale 'b'.
        Assumes r > 0 and b > 0.

        The PDF is: p(x) = 1/(2 b z) exp(-x/b) if x > r else 0.
        z = 1/2 exp(-r/b)
        """
        return r + abs(self.laplace(0, b))

    def _gauss_sum(self):
        """
        Return the sum of 'n' Gaussian random variates.

        The generating distribution of the returned results
        is normal with mean zero and variance self._n, i.e.,
        stdev self._sqrt_n
        """
        return sum(self._unsafe_rand.gauss() for _ in range(self._n))

    def _unsafe_random(self) -> float:
        """
        Provide a random variate uniform in the interval [0, 1).

        This merely accesses the underlying SystemRandom number generator,
        and does not add any privacy.
        """
        return self._unsafe_rand.random()

    def _normal_approx_to_binomial(self, n: int, p: float) -> int:
        """
        If K ~ B(n, p) and if np and n(1-p) are both large, then K is
        approximately N(np, sqrt(np(1-p))).
        Here 'large' means >> 10.

        TODO consider the Camp-Paulson normal approximation
            to the binomial distribution.
            E.g., see https://www.johndcook.com/blog/camp_paulson/
        """
        np = n * p
        sigma = math.sqrt(np * (1 - p))

        # This is the number of Gaussian variates we generate.
        # The math.log2(n) / 52 is an estimate of the amount of
        # precision required for 'n' relative to the precision
        # of a Python float (52 bits for mantissa).
        # We add _n to ensure the safety of the random variates,
        # as per Holohan & Braghin (2021).
        # This is a significant overestimate of the number of
        # draws required.
        num_of_variates = self._n + int(1 + math.log2(n) / 52)

        # Taking the average of many variates reduces the variance
        # by a factor equal to the number of variates, therefore
        # we need to increase the stdev of our source normal
        # distribution by sqrt(num_of_variates).
        sigma *= math.sqrt(num_of_variates)

        # We sum up rounded Gaussian variates as ints to
        # ameliorate precision issues of converting the underlying float
        # random variates into ints.
        k = sum(
            int(self._unsafe_rand.gauss(np, sigma) + 0.5)
            for _ in range(num_of_variates)
        )
        k //= num_of_variates

        # Enforce bounds, in the unlikely event this is needed.
        k = max(0, min(k, n))

        return k

    def _algorithm_bin(self, n: int, p: float) -> int:
        """
        Generate Binomial random variate k using 'Algorithm BIN' from:

        Ernst Stadlober, 1991 "Binomial Random Variate Generation: A
        Method Based On Ratios Of Uniforms". The Frontiers of Statistical
        Computation, Simulation, & Modelling. Volume 1 of the Proceedings
        of ICOSCO-1, The First International Conference on Statistical Computing.
        American Sciences Press, Inc.
        """

        # Ensure precondition is met
        large_p = p > 0.5
        if large_p:
            p = 1 - p

        b_precision = 1 + math.log10(n)  # heuristic for controlling precision (B in the paper)

        # Step 0
        q = 1 - p
        r = p / q
        mu = n * p
        t = (n + 1) * r
        f0 = q ** n
        b = min(n, int(mu + b_precision * math.sqrt(mu * q)))

        # Step 1
        u = self.random_open()
        k = 0
        f = f0

        while True:
            # Step 2
            if u <= f:
                break

            # Step 3
            k += 1
            if k > b:
                # Step 1 (again)
                u = self.random_open()
                k = 0
                f = f0
            else:
                u = u - f
                f = f * (t / k - r)
            # Back to step 2

        if large_p:
            k = n - k

        return k

    # Deprecated
    #
    # def _unsafe_randint(self, a: int, b: int) -> int:
    #     """
    #     Return random integer in range [a, b], including both end points.
    #
    #     This merely accesses the underlying SystemRandom number generator,
    #     and does not add any privacy.
    #     """
    #     return self._unsafe_rand.randint(a, b)
    #
    # def _binomial_farach_colton(self, n: int, p: float) -> int:
    #     """
    #     TODO: Farach-Colton & Tsai may provide a better method for
    #      efficiently and securely sampling the Binomial distribution.
    #
    #     Farach-Colton, M. and Tsai, M.T., 2015. Exact sublinear binomial sampling.
    #     Algorithmica 73(4), pp. 637-651.
    #     """
    #     ...
    #
    # def _binomial_half(self, n: int) -> int:
    #     """
    #     Generate binomial random variate k, with p = 0.5, using algorithm from:
    #
    #     K. Bringmann, F. Kuhn, et al., “Internal DLA: Efficient Simulation
    #     of a Physical Growth Model.” In: Proc. 41st International Colloquium
    #     on Automata, Languages, and Programming (ICALP '14), 2014.
    #     """
    #     if n < 4:
    #         return sum(self._unsafe_randint(0, 1) for _ in range(n))
    #
    #     if n % 2 == 1:
    #         return self._unsafe_randint(0, 1) + self._binomial_half(n - 1)
    #
    #     m = int(math.sqrt(n)) + 1
    #     while True:
    #         k = 0
    #         while self._unsafe_randint(0, 1) == 0:
    #             k += 1
    #         i = k * m + self._unsafe_randint(0, m - 1)
    #         if self._unsafe_randint(0, 1) == 0:
    #             ret = n // 2 + i
    #         else:
    #             ret = n // 2 - i - 1
    #         if ret < 0 or ret > n:
    #             continue
    #         expo = -self._rand.expovariate(1)
    #         p = (
    #             math.lgamma(n + 1)
    #             - math.lgamma(ret + 1)
    #             - math.lgamma((n - ret) + 1)
    #             + math.log(m)
    #             + math.log(2) * (k - n - 2)
    #         )
    #         if expo <= p:
    #             return ret
